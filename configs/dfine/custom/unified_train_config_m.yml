__include__: [
  '../../runtime.yml',
]

task: detection
output_dir: ./output/dfine_hgnetv2_m_custom_unified

# --- Global Config ---
# Define input size once. All other components will reference this.
eval_spatial_size: &eval_spatial_size [320, 320]
input_size: &input_size 320

# --- Dataset Config ---
evaluator:
  type: CocoEvaluator
  iou_types: ['bbox', ]

num_classes: 1
remap_mscoco_category: False

train_dataloader:
  type: DataLoader
  dataset:
    type: YOLOTxtDetection
    list_file: /media/ai/Data_SSD/yql/dataset/kc/num/train.txt
    transforms:
      type: Compose
      ops:
        - {type: RandomPhotometricDistort, p: 0.5}
        - {type: RandomZoomOut, fill: 0}
        # - {type: RandomIoUCrop, p: 0.8}
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: RandomHorizontalFlip}
        - {type: LetterBoxResize, size: *input_size} 
        - {type: PadToSize, size: *eval_spatial_size, fill: 0}
        # - {type: SanitizeBoundingBoxes, min_size: 1} # Redundant without CropConvertPILImage, dtype: 'float32', scale: True}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
        - {type: ConvertBoxes, fmt: 'cxcywh', normalize: True}
      policy:
        name: stop_epoch
        epoch: 40 # epoch in [71, ~) stop `ops`
        ops: ['RandomPhotometricDistort', 'RandomZoomOut']
  shuffle: False
  num_workers: 8
  drop_last: True
  pin_memory: True
  persistent_workers: True
  collate_fn:
    type: BatchImageCollateFunction
    base_size: *input_size
    base_size_repeat: 20
    stop_epoch: 40
    ema_restart_decay: 0.9999
  batch_size: 40 # Per-GPU batch size

val_dataloader:
  type: DataLoader
  dataset:
    type: YOLOTxtDetection
    list_file: /media/ai/Data_SSD/yql/dataset/kc/num/20230630/eval/eval.txt
    transforms:
      type: Compose
      ops:
        - {type: LetterBoxResize, size: *input_size}
        - {type: PadToSize, size: *eval_spatial_size, fill: 0}
        - {type: ConvertPILImage, dtype: 'float32', scale: True}
  shuffle: False
  num_workers: 4
  drop_last: False
  collate_fn:
    type: BatchImageCollateFunction
  batch_size: 40 # Per-GPU batch size


# --- Model Config (HGNetv2-M) ---
model: DFINE
criterion: DFINECriterion
postprocessor: DFINEPostProcessor

use_focal_loss: True
# eval_spatial_size: [320, 320] # Removed redundant definition, using anchor defined above if needed, or it's used by engine.
# Actually eval_spatial_size is often used by the solver/engine directly. 
# We keep the key at top level but use the anchor.

DFINE:
  backbone: HGNetv2
  encoder: HybridEncoder
  decoder: DFINETransformer

HGNetv2:
  name: 'B2'
  return_idx: [1, 2, 3]
  freeze_at: -1
  freeze_norm: False
  use_lab: True
  pretrained: True
  local_model_dir: weight/hgnetv2/

HybridEncoder:
  in_channels: [384, 768, 1536]
  hidden_dim: 256
  depth_mult: 0.67
  expansion: 0.5
  feat_strides: [8, 16, 32]
  use_encoder_idx: [2]
  num_encoder_layers: 1
  nhead: 8
  dim_feedforward: 1024
  dropout: 0.
  enc_act: 'gelu'
  act: 'silu'

DFINETransformer:
  feat_channels: [256, 256, 256]
  feat_strides: [8, 16, 32]
  hidden_dim: 256
  num_levels: 3
  num_layers: 4
  eval_idx: -1
  num_queries: 300
  num_denoising: 100
  label_noise_ratio: 0.5
  box_noise_scale: 1.0
  reg_max: 32
  reg_scale: 4
  layer_scale: 1
  num_points: [3, 6, 3]
  cross_attn_method: default
  query_select_method: default

DFINEPostProcessor:
  num_top_queries: 300
  eval_size: *eval_spatial_size # Must match Resize/Pad size for correct coordinate restoration

DFINECriterion:
  weight_dict: {loss_vfl: 1, loss_bbox: 5, loss_giou: 2, loss_fgl: 0.15, loss_ddf: 1.5}
  losses: ['vfl', 'boxes', 'local']
  alpha: 0.75
  gamma: 3.0
  reg_max: 32
  matcher:
    type: HungarianMatcher
    weight_dict: {cost_class: 2, cost_bbox: 5, cost_giou: 2}
    alpha: 0.25
    gamma: 3.0

# --- Optimizer & Training Config ---
use_amp: True
use_ema: True
ema:
  type: ModelEMA
  decay: 0.9999
  warmups: 300 # Scaled down for batch_size 40 (approx 500 * 24/40)
  start: 0

epochs: 50
clip_max_norm: 0.1

optimizer:
  type: AdamW
  params:
    -
      params: '^(?=.*backbone)(?!.*norm|bn).*$'
      lr: 0.00001
    -
      params: '^(?=.*backbone)(?=.*norm|bn).*$'
      lr: 0.00001
      weight_decay: 0.
    -
      params: '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn|bias)).*$'
      weight_decay: 0.
  lr: 0.0001
  betas: [0.9, 0.999]
  weight_decay: 0.0005

lr_scheduler:
  type: CosineAnnealingLR
  T_max: 20
  eta_min: 0.000004

lr_warmup_scheduler:
  type: LinearWarmup
  warmup_duration: 150 # Scaled down for batch_size 40 (approx 250 * 24/40)
